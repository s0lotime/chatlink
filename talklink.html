<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Chatlink WebRTC Call - Dark Mode + Pickup/Decline</title>
<style>
  /* Dark mode base */
  body {
    margin: 0; padding: 0;
    background: #121212;
    color: #eee;
    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    display: flex;
    flex-direction: column;
    align-items: center;
    min-height: 100vh;
  }
  h1, h2 {
    margin: 1rem 0 0.5rem 0;
  }

  #idOutput {
    font-weight: bold;
    color: #61dafb;
    user-select: text;
  }

  .video-container {
    display: flex;
    justify-content: center;
    gap: 1rem;
    flex-wrap: wrap;
    margin-top: 1rem;
    width: 90%;
    max-width: 900px;
  }
  video, audio {
    background: #222;
    border: 2px solid #444;
    border-radius: 8px;
    box-shadow: 0 0 8px #222;
  }
  video {
    width: 45%;
    height: auto;
  }
  audio {
    width: 45%;
    outline: none;
  }

  /* Equalizer canvas */
  #equalizer {
    width: 90%;
    max-width: 900px;
    height: 100px;
    background-color: #111;
    margin: 1.5rem auto;
    border-radius: 8px;
    display: block;
  }

  /* Controls */
  .controls {
    margin-top: 1rem;
    display: flex;
    flex-wrap: wrap;
    justify-content: center;
    gap: 0.75rem;
  }

  input#targetId {
    padding: 0.5rem;
    font-size: 1rem;
    border-radius: 6px;
    border: none;
    width: 200px;
    max-width: 90vw;
  }

  button {
    background: #222;
    border: 1.5px solid #444;
    border-radius: 6px;
    color: #eee;
    padding: 0.5rem 1rem;
    font-size: 1rem;
    cursor: pointer;
    transition: all 0.2s ease-in-out;
  }
  button:hover:not(:disabled) {
    background: #61dafb;
    color: #121212;
    border-color: #61dafb;
  }
  button:disabled {
    cursor: not-allowed;
    opacity: 0.4;
  }

  /* Incoming call alert box */
  #incomingCallAlert {
    background: #222;
    border: 2px solid #f44336;
    border-radius: 8px;
    padding: 1rem 1.5rem;
    margin: 1rem auto;
    max-width: 400px;
    text-align: center;
    box-shadow: 0 0 10px #f44336;
    display: none;
  }
  #incomingCallAlert strong {
    display: block;
    margin-bottom: 1rem;
    color: #f44336;
    font-size: 1.2rem;
  }
  #incomingCallAlert button {
    margin: 0 0.5rem;
  }
</style>
</head>
<body>

<h1>Chatlink WebRTC Call with Equalizer</h1>
<h2 id="idOutput">My ID is ...</h2>

<div class="video-container">
  <video id="localVideo" autoplay playsinline muted></video>
  <video id="remoteVideo" autoplay playsinline></video>
</div>

<audio id="remoteAudio" autoplay></audio>

<canvas id="equalizer"></canvas>

<div class="controls">
  <input id="targetId" placeholder="Target client ID" autocomplete="off" />
  <button id="callBtn" disabled>Start Call</button>
  <button id="toggleAudio" disabled>Audio (On)</button>
  <button id="toggleVideo" disabled>Video (On)</button>
</div>

<div id="incomingCallAlert">
  <strong>Incoming Call from <span id="callerId"></span></strong>
  <button id="acceptCallBtn">Accept</button>
  <button id="declineCallBtn">Decline</button>
</div>

<script>
(async () => {
  const localVideo = document.getElementById("localVideo");
  const remoteVideo = document.getElementById("remoteVideo");
  const remoteAudio = document.getElementById("remoteAudio");
  const equalizerCanvas = document.getElementById("equalizer");
  const ctx = equalizerCanvas.getContext("2d");

  const targetIdInput = document.getElementById("targetId");
  const callBtn = document.getElementById("callBtn");
  const toggleAudioBtn = document.getElementById("toggleAudio");
  const toggleVideoBtn = document.getElementById("toggleVideo");

  const incomingCallAlert = document.getElementById("incomingCallAlert");
  const callerIdSpan = document.getElementById("callerId");
  const acceptCallBtn = document.getElementById("acceptCallBtn");
  const declineCallBtn = document.getElementById("declineCallBtn");

  let socket;
  let myId = null;
  let peer = null;
  let localStream = null;
  let audioTrack = null;
  let videoTrack = null;

  let incomingOffer = null;
  let incomingCallerId = null;
  let callActive = false;

  // Setup WebSocket connection
  function setupSocket() {
    socket = new WebSocket("wss://chatlink.space/messagerouting/call/connection?room=default");

    socket.addEventListener("open", () => {
      console.log("WebSocket connected");
    });

    socket.addEventListener("message", async event => {
      const msg = JSON.parse(event.data);
      console.log("Message received:", msg);

      if (msg.type === "welcome") {
        myId = msg.id;
        document.getElementById("idOutput").textContent = `My ID is: ${myId}`;
        callBtn.disabled = false;
      }

      if (msg.type === "offer") {
        if (callActive) {
          // Busy, auto decline
          sendMessage(msg.from, "decline");
          return;
        }
        incomingOffer = msg.payload;
        incomingCallerId = msg.from;
        showIncomingCall(incomingCallerId);
      }

      if (msg.type === "answer") {
        if (!peer) return;
        try {
          await peer.setRemoteDescription(new RTCSessionDescription(msg.payload));
        } catch (e) {
          console.error("Error setting remote description (answer):", e);
        }
      }

      if (msg.type === "ice") {
        if (!peer) return;
        try {
          await peer.addIceCandidate(new RTCIceCandidate(msg.payload));
        } catch (e) {
          console.error("Error adding ICE candidate:", e);
        }
      }

      if (msg.type === "decline") {
        alert("Call was declined by the other party.");
        resetCall();
      }
    });
  }

  // Send message over WebSocket
  function sendMessage(to, type, payload) {
    const message = { to, type, payload };
    socket.send(JSON.stringify(message));
  }

  // Create silent audio track fallback
  function createSilentAudioTrack() {
    const ctx = new AudioContext();
    const oscillator = ctx.createOscillator();
    const dst = oscillator.connect(ctx.createMediaStreamDestination());
    oscillator.start();
    const track = dst.stream.getAudioTracks()[0];
    return Object.assign(track, { enabled: true });
  }

  // Create peer connection with ICE config
  function createPeer() {
    const iceServers = [
      { urls: ["stun:stun.cloudflare.com:3478", "stun:stun.cloudflare.com:53"] },
      {
        urls: [
          "turn:turn.cloudflare.com:3478?transport=udp",
          "turn:turn.cloudflare.com:3478?transport=tcp",
          "turns:turn.cloudflare.com:5349?transport=tcp",
          "turn:turn.cloudflare.com:53?transport=udp",
          "turn:turn.cloudflare.com:80?transport=tcp",
          "turns:turn.cloudflare.com:443?transport=tcp"
        ],
        username: "g06029b93cd518b42c38009ea2d357ed52ef1fba78330a81c283fda35ee71131",
        credential: "98f92c527bea47961e372c68c6e2ae3234def2ea48947ca0fed5c2adf177567b"
      }
    ];

    const pc = new RTCPeerConnection({ iceServers });

    pc.onicecandidate = e => {
      if (e.candidate && peerTargetId) {
        sendMessage(peerTargetId, "ice", e.candidate);
      }
    };

    pc.ontrack = e => {
      // Separate audio and video streams for remote
      e.streams.forEach(stream => {
        // Check if stream contains video track(s)
        const videoTracks = stream.getVideoTracks();
        if (videoTracks.length > 0) {
          remoteVideo.srcObject = stream;
        }
        // Check if stream contains audio track(s)
        const audioTracks = stream.getAudioTracks();
        if (audioTracks.length > 0) {
          remoteAudio.srcObject = stream;
        }
      });
    };

    pc.onconnectionstatechange = () => {
      if (pc.connectionState === "disconnected" || pc.connectionState === "failed" || pc.connectionState === "closed") {
        console.log("Peer disconnected or closed");
        resetCall();
      }
    };

    return pc;
  }

  // Start local media stream
  async function startLocalStream() {
    try {
      const userStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });

      const audioTracks = userStream.getAudioTracks();
      const videoTracks = userStream.getVideoTracks();

      audioTrack = audioTracks[0] || createSilentAudioTrack();
      videoTrack = videoTracks[0] || null;

      const tracks = [audioTrack];
      if (videoTrack) tracks.push(videoTrack);

      localStream = new MediaStream(tracks);

      localVideo.srcObject = localStream;

      toggleAudioBtn.disabled = audioTracks.length === 0;
      toggleVideoBtn.disabled = videoTracks.length === 0;

    } catch (err) {
      console.error("Could not get user media", err);
      alert("Failed to get camera/microphone access.");
    }
  }

  // Call state
  let peerTargetId = null;

  // Initiate call (send offer)
  async function startCall() {
    if (!targetIdInput.value.trim()) {
      alert("Please enter the target client ID");
      return;
    }
    if (callActive) {
      alert("Call already in progress.");
      return;
    }
    peerTargetId = targetIdInput.value.trim();

    peer = createPeer();

    // Add local tracks to peer
    if (audioTrack) peer.addTrack(audioTrack, localStream);
    if (videoTrack) peer.addTrack(videoTrack, localStream);

    try {
      const offer = await peer.createOffer();
      await peer.setLocalDescription(offer);
      sendMessage(peerTargetId, "offer", offer);
      callActive = true;
      updateControlsForCall(true);
    } catch (e) {
      console.error("Failed to start call:", e);
    }
  }

  // Show incoming call UI
  function showIncomingCall(callerId) {
    callerIdSpan.textContent = callerId;
    incomingCallAlert.style.display = "block";
    // Play alert sound or flash title, etc. - could add here
  }

  // Hide incoming call UI
  function hideIncomingCall() {
    incomingCallAlert.style.display = "none";
    callerIdSpan.textContent = "";
  }

  // Accept incoming call
  async function acceptCall() {
    if (!incomingOffer || !incomingCallerId) return;

    peerTargetId = incomingCallerId;

    peer = createPeer();

    if (audioTrack) peer.addTrack(audioTrack, localStream);
    if (videoTrack) peer.addTrack(videoTrack, localStream);

    try {
      await peer.setRemoteDescription(new RTCSessionDescription(incomingOffer));
      const answer = await peer.createAnswer();
      await peer.setLocalDescription(answer);
      sendMessage(peerTargetId, "answer", answer);
      callActive = true;
      updateControlsForCall(true);
    } catch (e) {
      console.error("Error accepting call:", e);
    }

    incomingOffer = null;
    incomingCallerId = null;
    hideIncomingCall();
  }

  // Decline incoming call
  function declineCall() {
    if (incomingCallerId) {
      sendMessage(incomingCallerId, "decline");
    }
    incomingOffer = null;
    incomingCallerId = null;
    hideIncomingCall();
  }

  // Reset call state/UI
  function resetCall() {
    if (peer) {
      peer.close();
      peer = null;
    }
    peerTargetId = null;
    callActive = false;
    incomingOffer = null;
    incomingCallerId = null;
    hideIncomingCall();
    updateControlsForCall(false);

    remoteVideo.srcObject = null;
    remoteAudio.srcObject = null;
  }

  // Toggle audio on/off
  function toggleAudio() {
    if (!audioTrack) return;
    audioTrack.enabled = !audioTrack.enabled;
    toggleAudioBtn.textContent = `Audio (${audioTrack.enabled ? "On" : "Off"})`;
  }

  // Toggle video on/off
  function toggleVideo() {
    if (!videoTrack) return;
    videoTrack.enabled = !videoTrack.enabled;
    toggleVideoBtn.textContent = `Video (${videoTrack.enabled ? "On" : "Off"})`;
  }

  // Update controls based on call status
  function updateControlsForCall(inCall) {
    callBtn.disabled = inCall;
    targetIdInput.disabled = inCall;
    toggleAudioBtn.disabled = !inCall || !audioTrack;
    toggleVideoBtn.disabled = !inCall || !videoTrack;
  }

  // Equalizer visualizer setup
  function setupEqualizer() {
    const audioCtx = new AudioContext();
    const analyser = audioCtx.createAnalyser();
    analyser.fftSize = 64;
    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);

    // Connect local audio track to analyser
    if (audioTrack) {
      const source = audioCtx.createMediaStreamSource(new MediaStream([audioTrack]));
      source.connect(analyser);
    }

    function draw() {
      requestAnimationFrame(draw);

      analyser.getByteFrequencyData(dataArray);

      ctx.fillStyle = "#111";
      ctx.fillRect(0, 0, equalizerCanvas.width, equalizerCanvas.height);

      const barWidth = (equalizerCanvas.width / bufferLength) * 1.5;
      let x = 0;

      for (let i = 0; i < bufferLength; i++) {
        const barHeight = (dataArray[i] / 255) * equalizerCanvas.height;
        const hue = i * 5 + 120;
        ctx.fillStyle = `hsl(${hue}, 80%, 50%)`;
        ctx.fillRect(x, equalizerCanvas.height - barHeight, barWidth, barHeight);
        x += barWidth + 2;
      }
    }
    draw();
  }

  // Set canvas size responsively
  function resizeCanvas() {
    equalizerCanvas.width = equalizerCanvas.clientWidth * devicePixelRatio;
    equalizerCanvas.height = equalizerCanvas.clientHeight * devicePixelRatio;
    ctx.scale(devicePixelRatio, devicePixelRatio);
  }

  // Event listeners
  callBtn.addEventListener("click", startCall);
  toggleAudioBtn.addEventListener("click", toggleAudio);
  toggleVideoBtn.addEventListener("click", toggleVideo);
  acceptCallBtn.addEventListener("click", acceptCall);
  declineCallBtn.addEventListener("click", declineCall);

  window.addEventListener("resize", () => {
    resizeCanvas();
  });

  // Initialization
  resizeCanvas();
  setupSocket();
  await startLocalStream();
  setupEqualizer();

})();
</script>

</body>
</html>
